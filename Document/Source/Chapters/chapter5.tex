\chapter{Implementation and Assessment}
\label{chp:Implementation_and_Assessment}

All algorithms discussed in this work are realized in \mbox{MATLAB}, a programming language specialized on matrix manipulations.
It is especially useful for high-dimensional matrix operations, such as the ones for this work.
The following text explains the implementation of the theoretical models and concepts discussed in the previous chapters.
For the implementation, the goal was to make the pipeline as flexible as possible to support all kinds of light fields in different formats.

\section{Requirements}
\label{sec:requirements}

For the implementation and physical realization, some assumptions and requirements have to be formulated.
The input light field for the optimization algorithm is expected to be a five dimensional array $L$ with entries $L_{ijklc}$, where pairs $(i, j)$ and $(k, l)$ correspond to the angular- and spatial coordinates, and $c$ indexes the color channel. 
The data is normalized such that $L_{ijklc} \in \left[0, 1\right]$.
It is also assumed that the light field is rectified such that indices $i, j$ conform to global coordinates on the $(s, t)$-plane as explained in section~\ref{sec:light_field_aquisition}.
In addition, the baseline as well as the distance between the two planes are a required input for the system.

The attenuator is defined by the number of layers, resolution, size and thickness.
Each layer has the same dimensions and resolution and is modeled to be infinitely thin.
Also, the backlight is modeled as a constant white light field, $L_0 \equiv 1$.

\section{The Basic Procedure}
\label{sec:basic_procedure}

As described in section~\ref{sec:ray_casting}, the two virtual planes that parameterize the light field are placed relative to the attenuator and by ray casting, the entries of the propagation matrix $P$ are computed.
Next, the constrained optimization problem given in equation~\ref{eq:minimize_norm} is solved independently for each color channel using an iterative solver of choice, e.g. \mbox{SART}.
The outcome of each optimization is a vector $\alpha_c$ containing the attenuation values in the interval $\left[ 0, \infty \right)$ where $c = 1, 2, 3$ (red, green, blue) denotes the color channel.
The transmittance values are then obtained by element-wise exponentiation, $t = \exp(-\alpha)$, which holds values between zero and one.
Finally, the linearly indexed vector $t$ is reshaped so that the layers can be extracted as three-dimensional matrices and printed on transparencies.

In order to evaluate the attenuation masks, one has to compare the emitted light field $L^\ast = \exp(- P \alpha)$ with the original, $L$.
For instance, one could evaluate the squared 2-norm of the difference $L - L^\ast$ in each color channel.
However, this resulting number is not very meaningful because it also varies with the size of the light field, i.e. the angular and spatial resolution.
This makes it harder to compare the display quality between different light fields.
Thus, it is better to use a normalized figure such as the mean squared error \mbox{(MSE)} or the root-mean-square error \mbox{(RMSE)} defined as
\begin{equation*}
	\text{MSE} \coloneqq \frac{1}{n} \sum_{i = 1}^{n} (X - X^\ast)^2 = \frac{1}{n} \lVert X - X^\ast \rVert^2
	\quad \text{and} \quad
	\text{RMSE} \coloneqq \sqrt{\text{MSE}}
\end{equation*}
for vectors $X, X^\ast \in \mathbb{R}^n$.
To deal with the color channels, the \mbox{MSE} is computed for each color component and then averaged.
Another important quality measure in signal processing is the peak signal-to-noise ratio \mbox{(PSNR)} defined as
\begin{equation*}
	\text{PSNR} \coloneqq 10 \log_{10} \left(\frac{X_\text{max}^2}{\text{MSE}}\right),
\end{equation*}
where $X_\text{max}$ is the maximum value the image/color channel can hold, e.g. for 8-bit color channel representation this value would be 255.
It measures the loss of power in a reconstructed signal, with an additional adjustment for the human perception of error.
The use of this measure is motivated by the fact that \mbox{Layered 3D} is also about signal reconstruction, and the goal is to compare the original signal (light field) with the reconstructed one. 
Generally, a higher \mbox{PSNR} indicates greater image fidelity and conversely, a highly corrupted signal produces low \mbox{PSNR}.

The following sections present a variety of ideas and improvements that were implemented on top of the standard procedure explained above.
Next to that, the results are evaluated using the introduced error measures.

\section{Interpolation}
\label{sec:interpolation}

In addition to nearest neighbor interpolation indicated in equation~\ref{eq:pixel_shift_perspective_projection}, bilinear interpolation is incorporated into the pipeline in order to reduce artifacts.
For every ray, the value of the intersection point on the attenuation layer is represented as a linearly weighted sum of four neighboring pixels corresponding to the rounded indices.
Accordingly, instead of storing $N$ binary weights, each row of the propagation matrix now holds $4 N$ values.
Essentially, this just means that each ray in the log-light field is a linear combination of $4 N$ absobance values.
Due to the exponential propagation model, the interpolation in the log-domain translates to a multiplication of the transmittance simply by the exponatial law,
\begin{equation*}	
	\exp( \gamma \alpha_i + (1 - \gamma) \alpha_j ) = \exp( \gamma \alpha_i ) \exp( (1 - \gamma) \alpha_j ) = t_i^{\gamma} t_j^{1 - \gamma},
\end{equation*}
with $\gamma$ being the linear interpolation weight, $i$ and $j$ identifying the neighboring pixels which are the query points for the interpolation.

Unfortunately, the attempt of interpolation does not exhibit a significant increase in reconstruction quality.
For low resolution attenuation layers, the 

Alternatively, interpolation could be applied to the transmittance instead of the absorbance, but this requires a different optimization strategy.
Because of the non-linearity of the logarithm, the optimization problem can not simply be transformed into a linear equation.

In general, it is not entirely clear which interpolation strategy one should choose for such a problem.
The choice depends on a variety of physical factors as well as implementation specific restrictions.
For example, an inkjet printer produces slightly different attenuation masks than a laser printer.
One could estimate the point spread function (PSF) of the printer by observing the distribution of a single ink drop on the surface.
The interpolation weights should then be chosen according to the PSF.
This approach would take into account the very physical aspects of printing.
However, an accurate validation of this idea would introduce a lot of challenges because it requires accurate calibration and fabrication in order to compare the input light field with the displayed light field:
The measuring process would require two iterations, one with PSF interpolation and one without.
The attenuation layers need to be precisely aligned and placed in front of the capturing device (camera array, plenoptic camera etc.) such that the emited light rays directly correspond to the original light rays.

\section{Oversampling}
\label{sec:oversampling}


\section{Baseline Scaling and Back Projection}
\label{sec:baseline_scaling}

Often it is the case that the light field of interest has a depth range that does not match the depth of field of the display because of its fixed thickness.
As a consequence, objects outside the depth of field appear blurry as demonstrated in figure~\ref{fig:reconstruction_baseline_unscaled}
\begin{figure}[tb]
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/depth_compression/baseline_unscaled.tex}
		\caption{}
		\label{fig:reconstruction_baseline_unscaled}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/depth_compression/baseline_scaled.tex}
		\caption{}
		\label{fig:reconstruction_baseline_scaled_shifted}
	\end{subfigure}
	\caption[Baseline scaling]
			{Depth compression by means of baseline scaling.
			 Shown is the reconstructed central angular view without proper baseline scaling (a) and with scaling (b).
			 The light field used here is from the Stanford light field archive, \mbox{\url{http://lightfield.stanford.edu}}.}
	\label{fig:baseline_scaling}
\end{figure}
The reconstruction shows that cards in the front and back are blurred because they are virtually further away from the display, while the objects in the center are sharper.
This problem can be solved by virtually scaling the baseline while keeping all other distances the same.
The effect is that depth is compressed and hence objects appear to be squeezed in Z-direction.
But the question is: How should one chose the scale such that a desired range is sharp?
It is possible to solve this problem analytically, for example by using equation~\ref{eq:approx_upper_bound_spatial_cut_off} or ~\ref{eq:expected_upper_bound_spatial_cut_off}.
But often it is the case that the exact baseline is unknown, as it is for nearly all light fields used in this work.
The alternative, more visual way, is to back-project the light field to the layers by trial-and-error using the propagation matrix $P$ for a guessed baseline.
Although the propagation matrix must be computed for every trial, the back projection itself is fast because it is simply a matrix multiplication, 
\begin{equation*}\label{eq:back_projection}
	\beta = P^T L.
\end{equation*}
The outcome of this operation is a vector $\beta$ holding the values of $N$ refocused images where $N$ is the number of layers used.
In this way, one can control the depth compression by observing the focused parts of the light field in the top- and bottommost layer.
This method can also be used to align the display center with the center of the scene, or an arbitrary position if desired.

\section{Attenuator Tiling and Blending}
\label{sec:tiling_and_blending}

High resolution light fields can take up a significant amount of space in memory. 
For example, a light field taken with a Full HD camera from $17 \times 17$ angles would take up $1920 \cdot 1080 \cdot 17^2 \cdot 3 \cdot 8 / (1024^3) = 13.3947$ Gigabyte of memory, assuming \mbox{8-bit} color channels. 
In addition, the propagation matrix stores information about every pixel in the light field and thus, can take up Gigabytes of space depending on the resolution of the attenuation layers. 
The proposed approach divides the attenuation layers into tiles. 
Figure~\ref{fig:tiling_layout} shows how the tiles are laid out.
\begin{figure}[tb]
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/tiling/tiling_layout.tex}
		\caption{}
		\label{fig:tiling_layout}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/tiling/tiling_masks_sum.tex}
		\caption{}
		\label{fig:sum_of_quadratic_blending_masks}
	\end{subfigure}%
	\caption[Tiling layout]
			{(a) Layout of the tiles that cover the attenuation layers.
				 The pixel grid of size $R_x \times R_y$ is covered by tiles of $r_x \times r_y$ pixels with an overlap of $o_x$ in horizontal and $o_y$ in vertical direction.
			 (b) The sum of the per-tile quadratic blending masks used for the normalization.}
\end{figure}
\todo{fix gridlines in figure!} 
The inputs for the tiling algorithm are the resolution of the tiles $r = (r_x, r_y)$ and the overlap in horizontal and vertical direction, $o = (o_x, o_y)$. 
The tiles are then laid out in a grid beginning in the top left corner of the layer. 
The number of tiles needed to cover the plane can be calculated by 
\begin{equation}
	N_x = \left \lceil \dfrac{R_x - o_x}{r_x - o_x} \right \rceil
	\qquad 
	\text{and} 
	\qquad
	N_y = \left \lceil \dfrac{R_y - o_y}{r_y - o_y} \right \rceil.
\end{equation}
The combination of the same tile from each layer forms a subsection of the original layer stack and so, essentially a new attenuator of smaller size and lower resolution.
The optimization is then performed on every of the subsections with a smaller propagation matrix per tile (fewer columns). 
As a consequence, less memory is used to store attenuation layers and propagation data in each step.
In the end, the optimized tiles are put together to form the complete attenuation layers. 

In general, the borders of the attenuator contain less ray-propagation information and thus provide fewer constraints for the optimization. 
This introduces artifacts that are clearly visible in the reassembled layers as shown in figure~\ref{fig:comparison_tile_overlap_vs_no_overlap}.
\begin{figure}[tb]
	\centering
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/1.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/1.png}
		\caption{Layer 1}
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/2.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/2.png}
		\caption{Layer 2}
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/3.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/3.png}
		\caption{Layer 3}
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/blendingMaskSum.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/blendingMaskSum.png}
		\caption{Blending masks}
	\end{subfigure}%
	\caption[Impact of tile overlap on attenuation layers]
			{Impact of tile overlap on attenuation layers.
			 Top: Tiles have no overlap and grid artifacts are visible.
			 Bottom: With a 50\% overlap, the artifacts are no longer noticeable, but more tiles are needed.}
	\label{fig:comparison_tile_overlap_vs_no_overlap}
\end{figure} 
To solve this issue, the tiles have to overlap. 
In this case, when reassembling the layers from the tiles, the overlaps need to be blended with a mask:
After the optimization, each tile gets multiplied with a quadratic blending mask.
The finished layers are then obtained by summing the tiles and dividing by the sum of the blending masks shown in figure~\ref{fig:sum_of_quadratic_blending_masks}.
For the results shown in this work, a quadratic blending mask (weights increase quadratically towards the middle of the tile) was used.

\section{Performance of SART}
\label{sec:performance_of_SART}

The two iterative solvers described in section~\ref{sec:iterative_reconstruction} are compared in figure~\ref{fig:sart_vs_lsqlin} in terms of reconstruction error and runtime.
\begin{figure}[tb]
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/optimization_performance/iterations_vs_rmse.tex}
		\caption{}
		\label{fig:sart_lsqlin_iterations_vs_rmse}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/optimization_performance/iterations_vs_time.tex}
		\caption{}
		\label{fig:sart_lsqlin_iterations_vs_time}
	\end{subfigure}%
	\caption[Performance assessment of the optimization]
			{Performance assessment of the optimization.
			 The two iterative methods \mbox{SART} and \mbox{MATLAB's} linear least squares solver LSQLIN are compared in terms of \mbox{RMSE} (a) and runtime (b).
			 The input light field is the same as in figure~\ref{fig:baseline_scaling} and five attenuation layers were used.}
	\label{fig:sart_vs_lsqlin}
\end{figure}
Although the standard least squares solver uses fewer iterations compared to SART, the computation time is significantly longer.
For the specific experiment in the figure, both methods achieve the same RMSE with twenty iterations, but SART performs the twenty iterations in the same time as LSQLIN solves two iterations.
Furthermore, the simple update rule of SART allows for concurrent optimization in each color channel as opposed to LSQLIN, which needs to be run on every channel separately.
This shows that SART is a superior solver for this large scale layered 3D problem.
\begin{figure}[tb]
	\begin{subfigure}{\textwidth}
		\centering
		\input{../Figures/optimization_performance/layers_vs_psnr.tex}
		\caption{SART}
		\label{fig:sart_layers_vs_psnr}
	\end{subfigure}%
	\caption[Impact of layer count on \mbox{PSNR}]
			{Impact of layer count on the \mbox{PSNR}.
			 Performance comparison of the attenuation display for two different scenes from the Stanford light field archive.
			 The \mbox{PSNR} is evaluated against the number of layers.}
\end{figure}

\section{Contrast Sensitivity}

\begin{figure}[tb]
	\centering
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth, trim = {0 0 0 8cm}, clip]{../Figures/contrast/2layer/Reconstruction_of_view_(5,5)}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth, trim = {0 0 0 8cm}, clip]{../Figures/contrast/2layer/MSE_for_view_(5,5)}
		\caption{2 layers}
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth, trim = {0 0 0 8cm}, clip]{../Figures/contrast/5layer/Reconstruction_of_view_(5,5)}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth, trim = {0 0 0 8cm}, clip]{../Figures/contrast/5layer/MSE_for_view_(5,5)}
		\caption{5 layers}		
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.32\textwidth}
		\centering
		\includegraphics[width = \textwidth, trim = {0 0 0 8cm}, clip]{../Figures/contrast/5layer_2x_resolution/Reconstruction_of_view_(5,5)}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth, trim = {0 0 0 8cm}, clip]{../Figures/contrast/5layer_2x_resolution/MSE_for_view_(5,5)}
		\caption{5 layers, 2x resolution}
	\end{subfigure}%
	\caption[Contrast sensitivity analysis for layered 3D displays]
			{Contrast sensitivity analysis for layered 3D displays.
			 Shown are the simulated display projection from a viewing direction perpendicular to the display (top) and the absolute error (bottom).
			 The light field is constant in angle, contains increasing spatial frequency in horizontal direction and increasing contrast in vertical direction.}
	\label{fig:contrast_sensitivity}
\end{figure}

\section{Graphical User Interface}
\label{sec:GUI}

All functionalities of the pipeline are made available through a graphical user interface \mbox{(GUI)} for ease of use.
The main window is shown in figure~\ref{fig:gui_overview} for a particular use case.
\begin{figure}[tb]
	\includegraphics[width = \linewidth]{../Figures/gui/overview}
	\caption[Graphical user interface]
			{Graphical user interface for the \emph{Layered 3D} software developed with MATLAB.}
	\label{fig:gui_overview}
\end{figure}
A typical workflow involves three main steps, which correspond to the three columns in the window.
In the first step, the user imports a light field from either a folder of images or a \mbox{Lytro} container file.
The user can specify the projection type, camera- and image plane parameters as well as spatial- and angular downsampling in case memory is scarce.
After a successful import, the individual angular views are displayed in the preview window below.
The seconds step involves the configuration of the attenuator where the user enters the desired display thickness, size and resolution.
Before running the optimization, the user has the option to back-project the light field in case he/she want to ensure that the light fields depth range is aligned with the display.
In the last step, after optimization has completed, the user can preview the results (attenuation layers, reconstructed views or error images) in the window below or save them to disk.
Finally, a \mbox{PDF} file with the attenuation masks can be generated, ready to print on transparencies.

The software together with the GUI is available as an executable\footnote{The software available at \url{https://github.com/awaelchli/bachelor_project}.} 
and does not require a \mbox{MATLAB} installation in order to run.

\section{Benefits and Limitations}
\label{sec:benefits_limitations}

From a theoretical standpoint, the layered 3D architecture seems to be very promising.
The analysis shows that multiplicative displays encompass extended spectral support resulting in a higher depth of field compared to other automultiscopic systems.
The multi-layer design eliminates the trade-off between angular- and spatial resolution that is present with parallax barriers or integral imaging.
In practice, there are a few limitations that need to be addressed.
First off, to solve the multiplicative problem given by equation~\ref{eq:transmittance_layers} it is assumed that the transmission values are positive in order to solve the problem in a linear manner with the logarithm applied.
For the physical realization, this is of course a well justified assumption since negative transmission is not possible to achieve.
Nonetheless, the restriction to positive transmittance is reducing the space of solutions for optimal attenuation layers.
Althought it would require an entirely different approach, it is plausible to achieve better results if real valued transmission values were permitted.

The prototypes produced in the context of this thesis are suited for demonstration purposes, though the viewing angles are limited to a small range.
Unfortunately, experiments to show objects in virtual planes outside the displays enclosure were not successful.
Another challenge with display fabrication is the manual layer alignment.
The marks printed on the border of the layers help with alignment, but the process remains tedious and becomes increasingly harder with more layers.
Moreover, there are no universally best printer settings (amount of ink, drying time etc.) for printing on transparencies.
The settings have to be tuned by trial-and-error depending on the particular printer model and transparencies.
Also, Moir\'{e} does not seem to be a problem because of the natural blending of ink.

Contrast sensitivity

\section{Future Work and Improvements}
\label{sec:future_work}

The current implementation in MATLAB provides the necessary features in order to produce a static layered 3D display.
However, with greater effort a lot of operations can be made more efficient.
A GPU implementation of SART like the one from \cite{SARTGPU} could be incorporated in the software to accelerate the optimization process.
A parallelization of SART is possible because the update rule depends solely on matrix multiplication and addition.
The parallel approach would also eliminate the need of explicitly pre-computing the propagation matrix, which is a computationally- and memory intensive process.
Nonetheless, printing and layer alignment is time consuming and must be attacked with patience.


better printer
print on glass


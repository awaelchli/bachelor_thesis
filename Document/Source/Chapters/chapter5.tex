\chapter{Implementation and Assessment}
\label{chp:Implementation_and_Assessment}

All algorithms discussed in this work are realized in \mbox{MATLAB}, a programming language specialized on matrix manipulations.
It is especially useful for high-dimensional matrix operations, such as the ones for this work.
The following text explains the implementation of the theoretical models and concepts discussed in the previous chapters.
For the implementation, the goal was to make the pipeline as flexible as possible to support all kinds of light fields in different formats.

\section{Requirements}
\label{sec:requirements}

For the implementation and physical realization, some assumptions and requirements have to be formulated.
The input light field for the optimization algorithm is expected to be a five dimensional array $L$ with entries $L_{ijklc}$, where pairs $(i, j)$ and $(k, l)$ correspond to the angular- and spatial coordinates, and $c$ indexes the color channel. 
The data is normalized such that $L_{ijklc} \in \left[0, 1\right]$.
It is also assumed that the light field is rectified such that indices $i, j$ conform to global coordinates on the $(s, t)$-plane as explained in section~\ref{sec:light_field_aquisition}.
In addition, the baseline as well as the distance between the two planes are a required input for the system.

The attenuator is defined by the number of layers, resolution, size and thickness.
Each layer has the same dimensions and resolution and is modeled to be infinitely thin.
Also, the backlight is modeled as a constant white light field, $L_0 \equiv 1$.

\section{The Basic Procedure}
\label{sec:basic_procedure}

As described in section~\ref{sec:ray_casting}, the two virtual planes that parameterize the light field are placed relative to the attenuator and by ray casting, the entries of the propagation matrix $P$ are computed.
Next, the constrained optimization problem given in equation~\ref{eq:minimize_norm} is solved independently for each color channel using an iterative solver of choice, e.g. \mbox{SART}.
The outcome of each optimization is a vector $\alpha_c$ containing the attenuation values in the interval $\left[ 0, \infty \right)$ where $c = 1, 2, 3$ (red, green, blue) denotes the color channel.
The transmittance values are then obtained by element-wise exponentiation, $t = \exp(-\alpha)$, which holds values between zero and one.
Finally, the linearly indexed vector $t$ is reshaped so that the layers can be extracted as three-dimensional matrices and printed on transparencies.

In order to evaluate the attenuation masks, one has to compare the emitted light field $L^\ast = \exp(- P \alpha)$ with the original, $L$.
For instance, one could evaluate the squared 2-norm of the difference $L - L^\ast$ in each color channel.
However, this resulting number is not very meaningful because it also varies with the size of the light field, i.e. the angular and spatial resolution.
This makes it harder to compare the display quality between different light fields.
Thus, it is better to use a normalized figure such as the mean squared error \mbox{(MSE)} or the root-mean-square error \mbox{(RMSE)} defined as
\begin{equation*}
	\text{MSE} \coloneqq \frac{1}{n} \sum_{i = 1}^{n} (X - X^\ast)^2 = \frac{1}{n} \lVert X - X^\ast \rVert^2
	\quad \text{and} \quad
	\text{RMSE} \coloneqq \sqrt{\text{MSE}}
\end{equation*}
for vectors $X, X^\ast \in \mathbb{R}^n$.
To deal with the color channels, the \mbox{MSE} is computed for each color component and then averaged.
Another important quality measure in signal processing is the peak signal-to-noise ratio \mbox{(PSNR)} defined as
\begin{equation*}
	\text{PSNR} \coloneqq 10 \log_{10} \left(\frac{X_\text{max}^2}{\text{MSE}}\right),
\end{equation*}
where $X_\text{max}$ is the maximum value the image/color channel can hold, e.g. for 8-bit color channel representation this value would be 255.
It measures the loss of power in a reconstructed signal, with an additional adjustment for the human perception of error.
The use of this measure is motivated by the fact that \mbox{Layered 3D} is also about signal reconstruction, and the goal is to compare the original signal (light field) with the reconstructed one. 
Generally, a higher \mbox{PSNR} indicates greater image fidelity and conversely, a highly corrupted signal produces low \mbox{PSNR}.

The following sections present a variety of ideas and improvements that were implemented on top of the standard procedure explained above.
Next to that, the results are evaluated using the introduced error measures.

\section{Oversampling}
\label{sec:oversampling}

\section{Baseline Scaling and Back Projection}
\label{sec:baseline_scaling}

Often it is the case that the light field of interest has a depth range that does not match the depth of field of the display because of its fixed thickness.
As a consequence, objects outside the depth of field appear blurry as demonstrated in figure~\ref{fig:reconstruction_baseline_unscaled}
\begin{figure}[tb]
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/depth_compression/baseline_unscaled.tex}
		\caption{}
		\label{fig:reconstruction_baseline_unscaled}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/depth_compression/baseline_scaled.tex}
		\caption{}
		\label{fig:reconstruction_baseline_scaled_shifted}
	\end{subfigure}
	\caption[Baseline scaling]
			{Depth compression by means of baseline scaling.
			 Shown is the reconstructed central angular view without proper baseline scaling (a) and with scaling (b).
			 The light field used here is from the Stanford light field archive, \mbox{\url{http://lightfield.stanford.edu}}.}
	\label{fig:baseline_scaling}
\end{figure}
The reconstruction shows that cards in the front and back are blurred because they are virtually further away from the display, while the objects in the center are sharper.
This problem can be solved by virtually scaling the baseline while keeping all other distances the same.
The effect is that depth is compressed and thus objects appear to be squeezed in Z-direction.

\todo{Explain back-projection.}

\section{Attenuator Tiling and Blending}
\label{sec:tiling_and_blending}

High resolution light fields can take up a significant amount of space in memory. 
For example, a light field taken with a Full HD camera from $17 \times 17$ angles would take up $1920 \cdot 1080 \cdot 17^2 \cdot 3 \cdot 8 / (1024^3) = 13.3947$ Gigabyte of memory, assuming \mbox{8-bit} color channels. 
In addition, the propagation matrix stores information about every pixel in the light field and thus, can take up Gigabytes of space depending on the resolution of the attenuation layers. 
The proposed approach divides the attenuation layers into tiles. 
Figure~\ref{fig:tiling_layout} shows how the tiles are laid out.
\begin{figure}[tb]
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/tiling/tiling_layout.tex}
		\caption{}
		\label{fig:tiling_layout}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/tiling/tiling_masks_sum.tex}
		\caption{}
		\label{fig:sum_of_quadratic_blending_masks}
	\end{subfigure}%
	\caption[Tiling layout]
			{(a) Layout of the tiles that cover the attenuation layers.
				 The pixel grid of size $R_x \times R_y$ is covered by tiles of $r_x \times r_y$ pixels with an overlap of $o_x$ in horizontal and $o_y$ in vertical direction.
			 (b) The sum of the per-tile quadratic blending masks used for the normalization.}
\end{figure} 
The inputs for the tiling algorithm are the resolution of the tiles $r = (r_x, r_y)$ and the overlap in horizontal and vertical direction, $o = (o_x, o_y)$. 
The tiles are then laid out in a grid beginning in the top left corner of the layer. 
The number of tiles needed to cover the plane can be calculated by 
\begin{equation}
	N_x = \left \lceil \dfrac{R_x - o_x}{r_x - o_x} \right \rceil
	\qquad 
	\text{and} 
	\qquad
	N_y = \left \lceil \dfrac{R_y - o_y}{r_y - o_y} \right \rceil.
\end{equation}
The combination of the same tile from each layer forms a subsection of the original layer stack and so, essentially a new attenuator of smaller size and lower resolution.
The optimization is then performed on every of the subsections with a smaller propagation matrix per tile (fewer columns). 
As a consequence, less memory is used to store attenuation layers and propagation data in each step.
In the end, the optimized tiles are put together to form the complete attenuation layers. 

In general, the borders of the attenuator contain less ray-propagation information and thus provide fewer constraints for the optimization. 
This introduces artifacts that are clearly visible in the reassembled layers as shown in figure~\ref{fig:comparison_tile_overlap_vs_no_overlap}.
\begin{figure}[tb]
	\centering
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/1.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/1.png}
		\caption{Layer 1}
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/2.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/2.png}
		\caption{Layer 2}
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/3.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/3.png}
		\caption{Layer 3}
	\end{subfigure}\hspace{0.15cm}%
	\begin{subfigure}{0.23\textwidth}
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles3x3x200x200_no_overlap_3_layers/blendingMaskSum.png}
		
		\vspace{0.15cm}
		
		\includegraphics[width = \textwidth]{../Figures/tiling/tarot_tiles5x5x200x200_overlap0.5_3_layers/blendingMaskSum.png}
		\caption{Blending masks}
	\end{subfigure}%
	\caption[Impact of tile overlap on attenuation layers]
			{Impact of tile overlap on attenuation layers.
			 Top: Tiles have no overlap and grid artifacts are visible.
			 Bottom: With a 50\% overlap, the artifacts are no longer noticeable, but more tiles are needed.}
	\label{fig:comparison_tile_overlap_vs_no_overlap}
\end{figure} 
To solve this issue, the tiles have to overlap. 
In this case, when reassembling the layers from the tiles, the overlaps need to be blended with a mask:
After the optimization, each tile gets multiplied with a quadratic blending mask.
The finished layers are then obtained by summing the tiles and dividing by the sum of the blending masks shown in figure~\ref{fig:sum_of_quadratic_blending_masks}.
For the results shown in this work, a quadratic blending mask (weights increase quadratically towards the middle of the tile) was used.

\section{Performance of SART}
\label{sec:performance_of_SART}

The two iterative solvers described in section~\ref{sec:iterative_reconstruction} are compared in figure~\ref{fig:sart_vs_lsqlin} in terms of reconstruction error and runtime.
\todo{fix gridlines in figure!}
\begin{figure}[tb]
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/optimization_performance/iterations_vs_rmse.tex}
		\caption{}
		\label{fig:sart_lsqlin_iterations_vs_rmse}
	\end{subfigure}%
	\begin{subfigure}{0.5\textwidth}
		\centering
		\input{../Figures/optimization_performance/iterations_vs_time.tex}
		\caption{}
		\label{fig:sart_lsqlin_iterations_vs_time}
	\end{subfigure}%
	\caption[Performance assessment of the optimization]
			{Performance assessment of the optimization.
			 The two iterative methods \mbox{SART} and \mbox{MATLAB's} linear least squares solver \emph{lsqlin} are compared in terms of \mbox{RMSE} (a) and runtime (b).
			 The input light field is the same as in figure~\ref{fig:baseline_scaling} and five attenuation layers were used.}
	\label{fig:sart_vs_lsqlin}
\end{figure}

\begin{figure}[tb]
	\begin{subfigure}{\textwidth}
		\centering
		\input{../Figures/optimization_performance/layers_vs_psnr.tex}
		\caption{SART}
		\label{fig:sart_layers_vs_psnr}
	\end{subfigure}%
	\caption[Impact of layer count on \mbox{PSNR}]
			{Impact of layer count on the \mbox{PSNR}.
			 Performance comparison of the attenuation display for two different scenes from the Stanford light field archive.
			 The \mbox{PSNR} is evaluated against the number of layers.}
\end{figure}

\section{Graphical User Interface}
\label{sec:GUI}

All functionalities of the pipeline are made available through a graphical user interface \mbox{(GUI)} for ease of use.
The main window is shown in figure~\ref{fig:gui_overview} for a particular use case.
\begin{figure}[tb]
	\includegraphics[width = \linewidth]{../Figures/gui/overview.png}
	\caption[Graphical user interface]
			{Graphical user interface for the \emph{Layered 3D} software developed with MATLAB.}
	\label{fig:gui_overview}
\end{figure}
A typical workflow involves three main steps, which correspond to the three columns in the window.
In the first step, the user imports a light field from either a folder of images or a \mbox{Lytro} container file.
The user can specify the projection type, camera- and image plane parameters as well as spatial- and angular downsampling in case memory is scarce.
After a successful import, the individual angular views are displayed in the preview window below.
The seconds step involves the configuration of the attenuator where the user enters the desired display thickness, size and resolution.
Before running the optimization, the user has the option to back-project the light field in case he/she want to ensure that the light fields depth range is aligned with the display.
In the last step, after optimization has completed, the user can preview the results (attenuation layers, reconstructed views or error images) in the window below or save them to disk.
Finally, a \mbox{PDF} file with the attenuation masks can be generated, ready to print on transparencies.

The software together with the GUI is available as an executable\footnote{The software available at \url{https://github.com/awaelchli/bachelor_project}.} 
and does not require a \mbox{MATLAB} installation in order to run.

\section{Benefits and Limitations}
\label{sec:benefits_limitations}

Contrast sensitivity

Optimization only for positive transmittance

\section{Future Work and Improvements}
\label{sec:future_work}

GPU implementation for sart / projection matrix construction, 
